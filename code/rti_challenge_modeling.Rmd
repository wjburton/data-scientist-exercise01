---
title: "R Notebook"
output: html_notebook
---

###Step 4: Variable Associations With The Response <br>

```{r}

#'Create bins containing equal sample sizes spread across a variable
#'@description Create bins containing equal sample sizes. If the density is not
#'uniform then generic cuts in the data will not produce equal sample sizes among
#'the cuts.
#'@param variable  Variable of interest
#'@param n  The sample size for each bin
create_equal_bins <- function(variable, n){
  place <- 1:length(variable)
  n_bins <- ceiling(length(variable)/n)
  binned_var <- rep(1:n_bins,n) %>% sort %>% .[1:length(variable)]
  data.frame(place, variable) %>%
    arrange(variable) %>%
    mutate(binned_var = binned_var) %>%
    group_by(binned_var) %>%
    mutate(point = median(variable)) %>%
    ungroup() %>%
    arrange(place) -> out
  return(out)
}



#`Visualize the relationship between a variable and the response
#' @description plot the variable against the rolling percent of warm leads
#' @param variable Variable of interest
#' @param response Binary response variable
#' @param roll_n  rolling window on which to calculate the percent
#' @param variable_name independent variable
#' @return A visualization of the association between the variable and the response
#' @export
plot_rolling_mean <- function(variable, response, roll_n = 50, variable_name = 'variable'){
  data.frame(variable, response) %>%
    arrange(variable) %>%
    mutate(roll_pct_warm = zoo::rollmean(response, k = roll_n,
                                         align = 'center', fill = NA)) -> plot_roll_mean
    print(ggplot(plot_roll_mean, aes(x = variable, y = roll_pct_warm)) + geom_line() +
            xlab(variable_name))

}


#'Plot a continuous variable against a binary response
#'@description Plot a continuous variable against a binary response by
#'binning the variables and looking at the proportion of of the response in each bin
#'@param variable  A binned version of the continuous variable
#'@param n The number of datapoints for each condensed point
#'@param response Binary response variable
#'@param out Output the data used to create the plot or not. Accepts values of TRUE or FALSE
#'@param max_term The name of the independent variable, will become the x-axis title
#'@param max_poly_degree The highest degree of polynomial to use for modeling
#'@param variable_name Name of the variable, Will be the title of the x-axis
#'@param jitter_height The random jitter of the actual points. the default may be too large or small
#'@param log_odds Should the y-axis be in terms of log odds or probability. T = log odds, F = Probability
#'@export
plot_continuous <- function(variable, n = 30, response, out = F,
                            max_poly_degree = 1, variable_name = 'variable',
                            jitter_height = 0.1, log_odds = T){

  df <- create_equal_bins(variable, n)
  df <- data.frame(df, response) %>% na.omit()
  df %>%
  group_by(point) %>%
  summarise(prob_warm = sum(response)/n(),
            n = n()) %>%
  mutate(odds = prob_warm/(1-prob_warm)) %>%
  mutate(log_odds = log(odds)) -> association_tbl

  log_mod <- glm(response ~ poly(variable,max_poly_degree),data = df, family = "binomial")
  probs <- predict(log_mod , type = 'response')
  df$pred_prob <- probs
  df$pred_log_odds <- log(probs/(1-probs))

  max_log_odds <- max(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)])
  min_log_odds <- min(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)])
  add <- max(abs(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)]))


  if(log_odds == T){
    df$plot_point <- ifelse(df$response == 1, max_log_odds + .1*add,
                            min_log_odds - .1*add)

    print(ggplot()+ geom_point(aes(x = association_tbl$point, y = association_tbl$log_odds)) +
            geom_line(aes(x = df$variable, y = df$pred_log_odds))+
            geom_jitter(aes(x = df$variable, y = df$plot_point),
                           color = 'blue', alpha = .05, height = jitter_height, width = 0) +
            xlab(variable_name) + ylab('log odds of being a warm prospect'))
  } else{
    df$plot_point <- ifelse(df$response == 1,max(df$pred_prob) + 0.15, min(df$pred_prob) - 0.15 )
    print(ggplot()+ geom_point(aes(x = association_tbl$point, y = association_tbl$prob_warm)) +
            geom_line(aes(x = df$variable, y = df$pred_prob))+
            geom_jitter(aes(x = df$variable, y = df$plot_point),
                        color = 'blue', alpha = .05, height = jitter_height, width = 0) +
            xlab(variable_name) + ylab('probability of being a warm prospect'))
  }

  if(out == T){
    return(list('points' = association_tbl, 'line' = df))
  }
}



#' Plot overlaying density plots of the variable against the response
#' @description Identify separation created by the independent variable on the response
#' @param variable independent variable
#' @param response response variable
#' @param variable_name name of independent variable or x-axis title
#' @export
plot_density <- function(variable, response, variable_name = 'variable'){
    data.frame(variable, response) %>%
    mutate(response = factor(response)) %>%
    rename(over_50k = response) -> density_plot

    print(ggplot(density_plot, aes(x = variable, fill = over_50k)) + geom_density(alpha = 0.2)+
      xlab(variable_name) + scale_fill_manual(values=c("blue", "red")))
}
```


```{r}
library(tidyverse)
train <- read_csv('C:/Users/Will/Documents/MSA/jobs/rti_challenge/data-scientist-exercise01/data/train.csv')

train %>%
  mutate_each(funs(factor(.)), -c(age:hours_week)) %>% 
  mutate(over_50k = as.numeric(as.character(over_50k))) -> train

```

```{r}
plot_continuous(train$age, n = 300, response = train$over_50k, max_poly_degree = 3, log_odds = F, jitter_height = .025)
```

```{r}
plot_continuous(train$education_num, n = 100, response = train$over_50k, max_poly_degree = 1, log_odds = T)
```

Combine education numbers less than highschool grad into one level.
This association is approximately linear. I don't see a need to estimate a coefficient for each level.
```{r}
train %>% 
  mutate(education_num = ifelse(education_num < 8, 7, education_num)) -> train2
plot_continuous(train2$education_num, n = 100, response = train2$over_50k, max_poly_degree = 1, log_odds = T)
```
<br>

This variable has an outlier at 99,999 that is causing some problems. Lets log scale the variable and filter
so we are just looking at values > 0.
```{r}
plot_continuous(train$capital_gain , n = 100, response = train$over_50k, max_poly_degree = 1, log_odds = T)
```



Great looking separation here
```{r}
train %>% 
  filter(capital_gain > 0) -> train2
plot_continuous(log(train2$capital_gain + 1), n = 100, response = train2$over_50k, max_poly_degree = 1, log_odds = F)
```


Same data as above, this time looking at the difference in density distributions
```{r}
train %>% 
  filter(capital_gain > 0) -> train2
plot_density(log(train2$capital_gain + 1), response = train2$over_50k)
```


Lets take at a look at the association filtering the values equal to 0
```{r}
plot_continuous(train$capital_loss + 1, n = 30, response = train$over_50k, max_poly_degree = 1, log_odds = T)
plot_density(train$capital_loss, response = train$over_50k)
```
```{r}
train %>% 
  filter(capital_loss > 0) -> train2
plot_continuous(log(train2$capital_loss + 1), n = 30, response = train2$over_50k, max_poly_degree = 1, log_odds = F)
```

Theres really not much separation here.  Instead I'll convert this variable to be categorical. 0 if equal to 0, and 1 if greater than 0
```{r}
plot_density(log(train2$capital_loss + 1), response = train2$over_50k)
```